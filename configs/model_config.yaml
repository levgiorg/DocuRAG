# DocuRAG Model Configuration

# LLM Configuration
llm_model: "gemma3n:e2b"
ollama_base_url: "http://localhost:11434"
max_tokens: 2048
temperature: 0.7

# Embedding Configuration
embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
device: "auto"  # auto, cpu, cuda